{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRYy+VzCgtWypUrTjgHYIS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anro607/word2vec_in_literature/blob/main/doribasil_will_WIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2023학년도 교과융합 탐구 보고서 - 고전문학에 워투벡을 얹어드셔보세요(가제)\n",
        "https://www.notion.so/ae8770f8f03e4028a746618d5074831c\n",
        "<-내 노션바로가기"
      ],
      "metadata": {
        "id": "Ft0On8DWpM4l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "FxbcHp32e7hu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36eda64b-fba1-4697-8550-048341cf6223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "#웹 크롤\n",
        "import requests\n",
        "\n",
        "#전처리\n",
        "import re\n",
        "import zipfile\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "#워드투벡\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 웹 크롤링, 문자열 인덱싱으로 전처리하기"
      ],
      "metadata": {
        "id": "MyMjF9xt23N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#웹 크롤링을 사용해 gutenberq에서 업로드한 도리온 그레이의 초상 원문 가져오기\n",
        "\n",
        "url = \"https://www.gutenberg.org/cache/epub/174/pg174.txt\"  #Plain Text UTF-8\n",
        "all_html = requests.get(url)                                #가져오기\n",
        "print(all_html.text)                                        #제대로 가져와졌는지 확인"
      ],
      "metadata": {
        "id": "Q5SQtggTtZ1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dorion = all_html.text                                      #전체 내용 텍스트"
      ],
      "metadata": {
        "id": "R21COh51uuvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "현재 dorion 변수에는 도리온 그레이의 초상 원문 뿐 아닌 구텐베르크 각주, 오스카와일드 작가의 말, 목차 등 분석에 불필요한 요소가 포함됨.\n",
        "\n",
        "남겨야 할 것:\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; a. 본문\n",
        "\n",
        "삭제해야 할 것:\n",
        "1. 'The Project Gutenberg eBook of The Picture of Dorian Gray' ~ 'CHAPTER I.'\n",
        "2. 'CHAPTER II', 'CHAPTER III' 등 I~XX 챕터 문구.\n",
        "3. '  *** END OF THE PROJECT GUTENBERG EBOOK THE PICTURE OF DORIAN GRAY' ~ 끝까지\n",
        "\n",
        "이를 a만 남기고, 본문 사이 2를 없애는 과정으로 어쩌구"
      ],
      "metadata": {
        "id": "jpkiCMRYu-16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one = dorion.find('The studio was filled with the rich odour of roses,')                    #첫문장 (3314)\n",
        "three = dorion.find('THE END')                                                              #디엔드 (438613)\n",
        "print(one)\n",
        "print(three)"
      ],
      "metadata": {
        "id": "gYvIpA6Wwc3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f86894-d6e2-48fd-ecab-428fa67afcb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3314\n",
            "438613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "고로 dorion 문자열 변수에서 0\\~3314 인덱스와 438613\\~끝 인덱스를 잘라야 하기에\n",
        "반대로 3314\\~438612 인덱스를 남길 것이다.\n",
        "\n",
        "(438613이 아닌 438612을 잘라야 THE END의 'T'가 사라짐)"
      ],
      "metadata": {
        "id": "p8P-e9mZy_5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dorion = dorion[3314: 438612]\n",
        "print(dorion)"
      ],
      "metadata": {
        "id": "MnyJhilby-sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "챕터 표기를 포함한 본문을 뽑아냄!"
      ],
      "metadata": {
        "id": "TCGwo0-C3Nje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chapter = ['CHAPTER II.','CHAPTER III.','CHAPTER IV.','CHAPTER V.','CHAPTER VI.'\n",
        "          ,'CHAPTER VII.','CHAPTER VIII.','CHAPTER IX.','CHAPTER X.','CHAPTER XI.'\n",
        "          ,'CHAPTER XII.','CHAPTER XIII.','CHAPTER XIV.','CHAPTER XV.','CHAPTER XVI.',\n",
        "           'CHAPTER XVII.','CHAPTER XVIII.','CHAPTER XIX.','CHAPTER XX.']                 #챕터리스트리스트 엌ㅋㅋ\n",
        "dorion = a                                                                                     #원본 보호를 위한 임시 변수\n",
        "for i in chapter:\n",
        "  a = a.replace(i,'')                                                                     #제거\n",
        "\n",
        "print(a.find('CHAPTER'))                                                                  #잘 제거됐는지 확인(-1은 해당 문자가 없다는 뜻!)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F9BxxKf3Mfr",
        "outputId": "ee7e9f60-e46b-4d61-af1f-279696de0133"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "필요한 요소만 남기는 일에 성공했으니 이제 진짜 토큰화를 해보자.\n",
        "\n",
        "참고한 글 = https://wikidocs.net/21698"
      ],
      "metadata": {
        "id": "P_Iy5tvx6Mle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 토큰화"
      ],
      "metadata": {
        "id": "5eBtKpRX52ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_first = sent_tokenize(a)                                                     #토큰화 준비\n",
        "\n",
        "normalized_text = []                                                               #변환한 문장을 넣을 리스트\n",
        "for string in token_first:\n",
        "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())                           #각 문장의 구두점을 제거하고, 대문자를 소문자로 변환\n",
        "     normalized_text.append(tokens)\n",
        "\n",
        "\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]                 #토큰화 수행\n",
        "\n",
        "print('총 샘플의 개수 : {}'.format(len(result)))\n",
        "for line in result[:3]:\n",
        "    print(line)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym-PhtBhf2Ku",
        "outputId": "bcac46ad-3120-4444-eb0d-3f50bb0b4eae"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수 : 5373\n",
            "['the', 'studio', 'was', 'filled', 'with', 'the', 'rich', 'odour', 'of', 'roses', 'and', 'when', 'the', 'light', 'summer', 'wind', 'stirred', 'amidst', 'the', 'trees', 'of', 'the', 'garden', 'there', 'came', 'through', 'the', 'open', 'door', 'the', 'heavy', 'scent', 'of', 'the', 'lilac', 'or', 'the', 'more', 'delicate', 'perfume', 'of', 'the', 'pink', 'flowering', 'thorn']\n",
            "['from', 'the', 'corner', 'of', 'the', 'divan', 'of', 'persian', 'saddle', 'bags', 'on', 'which', 'he', 'was', 'lying', 'smoking', 'as', 'was', 'his', 'custom', 'innumerable', 'cigarettes', 'lord', 'henry', 'wotton', 'could', 'just', 'catch', 'the', 'gleam', 'of', 'the', 'honey', 'sweet', 'and', 'honey', 'coloured', 'blossoms', 'of', 'a', 'laburnum', 'whose', 'tremulous', 'branches', 'seemed', 'hardly', 'able', 'to', 'bear', 'the', 'burden', 'of', 'a', 'beauty', 'so', 'flamelike', 'as', 'theirs', 'and', 'now', 'and', 'then', 'the', 'fantastic', 'shadows', 'of', 'birds', 'in', 'flight', 'flitted', 'across', 'the', 'long', 'tussore', 'silk', 'curtains', 'that', 'were', 'stretched', 'in', 'front', 'of', 'the', 'huge', 'window', 'producing', 'a', 'kind', 'of', 'momentary', 'japanese', 'effect', 'and', 'making', 'him', 'think', 'of', 'those', 'pallid', 'jade', 'faced', 'painters', 'of', 'tokyo', 'who', 'through', 'the', 'medium', 'of', 'an', 'art', 'that', 'is', 'necessarily', 'immobile', 'seek', 'to', 'convey', 'the', 'sense', 'of', 'swiftness', 'and', 'motion']\n",
            "['the', 'sullen', 'murmur', 'of', 'the', 'bees', 'shouldering', 'their', 'way', 'through', 'the', 'long', 'unmown', 'grass', 'or', 'circling', 'with', 'monotonous', 'insistence', 'round', 'the', 'dusty', 'gilt', 'horns', 'of', 'the', 'straggling', 'woodbine', 'seemed', 'to', 'make', 'the', 'stillness', 'more', 'oppressive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "불용어 제거!! https://wikidocs.net/22530 참고\n",
        "\n"
      ],
      "metadata": {
        "id": "KO0KvELV77yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_result = result                                                                #원본 손실 방지\n",
        "stop_words = set(stopwords.words('english'))                                        #nltk에서 정한 영어 불용어\n",
        "#stop_words.update(['one', 'would'])                                #이후 테스트에서 확인한 제거되지 않은 불용어\n",
        "\n",
        "end_result = []                                                                     #불용어가 아닌 단어만 넣을 리스트\n",
        "for list_ in temp_result:\n",
        "  for word in list_ :\n",
        "    if word in stop_words:\n",
        "        list_.remove(word)\n",
        "  end_result.append(list_)\n",
        "\n",
        "print('총 샘플의 개수 : {}'.format(len(result)))\n",
        "for line in end_result[:3]:\n",
        "    print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBWW6uNj79dj",
        "outputId": "84d49619-cfb9-48e1-8099-deb3545de357"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수 : 5373\n",
            "['studio', 'filled', 'rich', 'odour', 'roses', 'light', 'summer', 'wind', 'stirred', 'amidst', 'trees', 'garden', 'came', 'open', 'door', 'heavy', 'scent', 'lilac', 'delicate', 'perfume', 'pink', 'flowering', 'thorn']\n",
            "['corner', 'divan', 'persian', 'saddle', 'bags', 'lying', 'smoking', 'custom', 'innumerable', 'cigarettes', 'lord', 'henry', 'wotton', 'could', 'catch', 'gleam', 'honey', 'sweet', 'honey', 'coloured', 'blossoms', 'laburnum', 'whose', 'tremulous', 'branches', 'seemed', 'hardly', 'able', 'bear', 'burden', 'beauty', 'flamelike', 'fantastic', 'shadows', 'birds', 'flight', 'flitted', 'across', 'long', 'tussore', 'silk', 'curtains', 'stretched', 'front', 'huge', 'window', 'producing', 'kind', 'momentary', 'japanese', 'effect', 'making', 'think', 'pallid', 'jade', 'faced', 'painters', 'tokyo', 'medium', 'art', 'necessarily', 'immobile', 'seek', 'convey', 'sense', 'swiftness', 'motion']\n",
            "['sullen', 'murmur', 'bees', 'shouldering', 'way', 'long', 'unmown', 'grass', 'circling', 'monotonous', 'insistence', 'round', 'dusty', 'gilt', 'horns', 'straggling', 'woodbine', 'seemed', 'make', 'stillness', 'oppressive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 워드 투 벡터 학습"
      ],
      "metadata": {
        "id": "YkUD_4Rp57hS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(sentences=end_result, vector_size=100, window=5, min_count=5, workers=4, sg=0)"
      ],
      "metadata": {
        "id": "ew4EIPCRldWK"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_result = model.wv.most_similar(\"man\")\n",
        "print(model_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcThO1XkG5za",
        "outputId": "26b33095-cba3-4300-fd28-81ddbc21a262"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('things', 0.9997504949569702), ('round', 0.9997105598449707), ('life', 0.9996974468231201), ('away', 0.9996891617774963), ('back', 0.999683678150177), ('time', 0.9996836185455322), ('men', 0.9996787905693054), ('old', 0.9996744990348816), ('face', 0.9996742010116577), ('long', 0.9996737837791443)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = input(\"찾고싶은 특정 단어의 유사단어 목록 : \")\n",
        "model_result = model.wv.most_similar(a)\n",
        "print(model_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtORDwd8mMy8",
        "outputId": "b34ddcdc-70c8-47b4-fa0e-525aa9c0695e"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "찾고싶은 특정 단어의 유사단어 목록 : face\n",
            "[('room', 0.9997405409812927), ('one', 0.9997245669364929), ('would', 0.9997214078903198), ('life', 0.9997110962867737), ('never', 0.9996740221977234), ('back', 0.9996738433837891), ('long', 0.9996717572212219), ('white', 0.9996669888496399), ('moment', 0.9996634125709534), ('away', 0.9996597766876221)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "밑에는 놀면서 저장한거.."
      ],
      "metadata": {
        "id": "LiF3oHjtpdww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.save_word2vec_format('doribasil') # 모델 저장 요건 픽쳐에 도리바질 다들가있더라ㄷㄷ"
      ],
      "metadata": {
        "id": "qHzAgHkWJ5Qr"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = KeyedVectors.load_word2vec_format(\"doribasil\") # 모델 로드...인데모델파일어딨는거임?!!!?!?!?!?"
      ],
      "metadata": {
        "id": "X0F0RSU8Kiyg"
      },
      "execution_count": 142,
      "outputs": []
    }
  ]
}